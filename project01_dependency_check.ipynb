{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "cuDNN version: 90100\n",
      "Number of CUDA devices: 1\n",
      "\n",
      "OpenCV version: 4.11.0\n",
      "\n",
      "Torchvision version: 0.21.0+cu124\n",
      "\n",
      "NumPy version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN version: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else 'Not available'}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "\n",
    "print(f\"\\nOpenCV version: {cv2.__version__}\")\n",
    "\n",
    "# Torchvision version\n",
    "print(f\"\\nTorchvision version: {torchvision.__version__}\")\n",
    "\n",
    "# NumPy version\n",
    "print(f\"\\nNumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "from configs import config\n",
    "\n",
    "print(config.SEED)  # 42\n",
    "print(config.TRAIN.HYP.EPOCHS)  # 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hr_dir': './data/DIV2K_train_HR', 'lr_dir': './data/DIV2K_train_LR_bicubic/X4', 'scale': 2, 'batch_size': 32, 'img_extensions': ['.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff'], 'jpeg_quality': 95, 'prefetch_batches': 2}\n"
     ]
    }
   ],
   "source": [
    "from configs import config_img_proc\n",
    "\n",
    "\n",
    "print(config_img_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing image directory: /data/users4/mesfahani1/project_dataset/datasets/Flickr2K/Flickr2K_HR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling images:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling images: 100%|██████████| 100/100 [00:10<00:00,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Directory Analysis Summary:\n",
      "Total files: 2650\n",
      "File formats: {'.png': 2650}\n",
      "Average dimensions: 1937.3x1434.0 pixels\n",
      "Dimension range: 1140x1032 to 2040x2040\n",
      "Average file size: 4.11 MB\n",
      "Estimated total size: 10.64 GB\n",
      "\n",
      "GPU Memory Estimates:\n",
      "Average memory per image (float32): 31.79 MB\n",
      "Batch memory requirement: 1017.36 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_files': 2650,\n",
       " 'formats': {'.png': 2650},\n",
       " 'dimensions': {'width': {'min': 1140, 'max': 2040, 'avg': 1937.28},\n",
       "  'height': {'min': 1032, 'max': 2040, 'avg': 1434.0},\n",
       "  'aspect_ratio': {'min': 0.5588235294117647,\n",
       "   'max': 1.9651162790697674,\n",
       "   'avg': 1.40369265912326}},\n",
       " 'file_size': {'min_mb': 1.2745800018310547,\n",
       "  'max_mb': 7.413661003112793,\n",
       "  'avg_mb': 4.112207450866699,\n",
       "  'estimated_total_gb': 10.641943110153079}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configs import config_img_proc\n",
    "from img_preprocessing import analyze_image_directory\n",
    "\n",
    "analyze_image_directory(config_img_proc.hr_dir,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import safetensors.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(\"Starting training...\")\n",
    "print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
